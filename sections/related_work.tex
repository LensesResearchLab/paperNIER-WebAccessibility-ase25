% !TEX root = main.tex

\section{Related Work}

\subsection{Web Accessibility compliance}

Conventional accessibility assessments primarily rely on static checkers that verify compliance with \ac{WCAG} criteria by inspecting HTML and CSS structures. Tools such as WAVE by WebAIM and IBM's NPM accessibility-checker exemplify this approach\cite{w3c_accessibility_tools_2025}. However, several studies have revealed significant limitations in these tools, pointing out existing tools often lack semantic awareness and fail to consider user perspectives, leading to incomplete or misleading results \cite{ara2024inclusive}. For instance, an evaluation of Bulgarian museum websites uncovered widespread accessibility failures despite technical correctness \cite{todorov2022accessibility}. Similarly, a study of Norwegian municipal websites found that although legislation mandated \ac{WCAG} compliance, issues such as low-quality alternative text persisted\cite{inal2025does}.

It is also important to note that \ac{WCAG} conformance varies by level, from A to AAA, meaning that a website labeled as “compliant” may still fall short of more stringent and specific accessibility standards. These findings underscore the need for real-time evaluations that reflect how visually impaired users interact with web interfaces. While automated tools are useful for early feedback, they are unable to identify all critical accessibility, functionality, and usability issues affecting this population \cite{todorov2022accessibility}.

\subsection{How Artificial Intelligence can be Integrated}

Recent work has proposed hybrid testing frameworks that attempt to improve automated evaluation by combining guidelines with heuristic or \ac{AI} enhanced methods. Machine learning can be used to identify ARIA landmarks in web applications, highlighting the potential of classification models to infer structure when developers omit key accessibility tags \cite{watanabe2024accessibility}. Likewise, various different types of machine learning models can be trained to identify and correct accessibility problems for helping websites follow accessibility guidelines, by looking at the source code and proposing viable solutions\cite{ramineni2024leveraging, kuszczynski2023comparative}. These efforts demonstrate growing awareness of the limitations of rule-based systems, but rely primarily on source code analysis.

\subsection{Autonomous AI agents}

The use of autonomous \ac{AI} agents to simulate user interaction with web interfaces has also been explored. UXAgent is a notable system that uses LLM agents to mimic thousands of diverse user personas in web usability studies. The agents interact with live websites via browser automation, providing qualitative and quantitative feedback that supports iterative UX design \cite{lu2025uxagent}. Complementing this, a GitHub Copilot extension that proactively embeds accessibility guidance into the coding workflow was also proposed \cite{mowar2025codea11y}. Their study shows how \ac{AI} assistants can suggest accessible UI code, highlight missing attributes, and prompt manual verification during development.

Another recent advancement in this area is AXNav, a system that interprets accessibility test instructions written in natural language and executes them on remote cloud devices using an LLM-based multiagent planner \cite{taeb2024axnav}. This approach demonstrates how LLM-driven agents can automate complex accessibility evaluations and provide actionable, context-rich feedback for developers.

Multimodal agents that adaptively present content based on user needs, transforming visual content into speech or simplified visuals for users with auditory or visual processing disorders were also proposed \cite{rajagopal2023design}. While not focused on web testing, their work shows how agents can model disability-specific interactions across modalities.

